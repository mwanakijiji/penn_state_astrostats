{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density Estimation (Smoothing) and Local Regression\n",
    "\n",
    "## Eric Feigelson \n",
    "## Summer School in Statistics for Astronomers\n",
    "\n",
    "\n",
    "**Adapted from R scripts in Appendix B,  *Modern Statistical Methods for Astronomy With R Applications*,  Eric D. Feigelson & G. Jogesh Babu 2012  http://astrostatistics.psu.edu/MSMA**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonparametric density estimation seeks an optimal continuous curve derived from low-dimensional point processes.  Astronomers call this 'smoothing the data'.  As with regression, a response variable ('y' axis) must be chosen so that the dispersion in that variable is minimized in some fashion.  Typically, a smoothing 'bandwidth' must be chosen or calculated.  Too large a bandwidth will miss structural details (increase bias) while too small a bandwidth will add noise (increase variance).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bivariate dataset with nonlinear relationship and heteroscedasticity\n",
    "\n",
    "set.seed(1)\n",
    "x <- sample(seq(0.01, 3, length.out=500))\n",
    "y <- 0.5*x + 0.3^(x^2) + rnorm(500, mean=0, sd=(0.05*(1+x^2)))\n",
    "xy <- cbind(x, y)\n",
    "plot(xy, pch=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a kernel density estimation with a Gaussian kernel chosen with the direct plug-in algorithm.  Here are two graphical displays of a continuous 3D function: a color image with contours, and a perspective plot.  \n",
    "\n",
    "> **Exercise 1:** Try different kernel widths: different 'scalest' parameter values within dpik.  Try 'locpoly', another smoothing functions in the KernSmooth package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I. Kernel density estimator with two visualizations\n",
    "\n",
    "if(!require(\"KernSmooth\", quietly=T)) {\n",
    "  install.packages(\"KernSmooth\", repos=\"https://cloud.r-project.org\", dependencies=TRUE)\n",
    "}; library(\"KernSmooth\")\n",
    "par(mfrow=c(1,2))\n",
    "dpik(x) ; dpik(y) \n",
    "smxy <- bkde2D(xy, bandwidth=c(0.5*dpik(x),0.5*dpik(y)))\n",
    "image(smxy$x1, smxy$x2, smxy$fhat, col=topo.colors(30), xlab='Xvar', ylab='Yvar', cex.lab=1.2)\n",
    "contour(smxy$x1, smxy$x2, smxy$fhat, add=T)\n",
    "persp(smxy$x1,smxy$x2, smxy$fhat, theta=100, phi=40, shade=0.1, col='green', xlab='Xvar', ylab='Yvar', zlab='Density')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Two spline fits\n",
    "\n",
    "We start with a standard cubic smoothing spline fit.  This function is based on code in a long-established Fortran package. We then proceed with a more modern spline regression that prunes knots based on the Bayesian Information Criterion likelihood measure, and computes spline function for any quantile of dispersion in the response variable.  This combination of local regression and quantile regression is particularly useful in astronomy where the errors (scatter) is often heteroscedastic (depends on the covariates) and asymmetrical.  \n",
    "\n",
    "> **Exercise:** Try different parameter options within COBS such as nknots, degree, lambda, and ic. See help(cobs).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classic spline fit \n",
    "\n",
    "cubsplxy <- smooth.spline(log10(xy))\n",
    "plot(log10(xy), pch=20, cex=0.5, ylim=c(-0.7, 0.4), xlab='log(Xvar)', \n",
    "     ylab='log(Yvar)', main='Cubic spline fit')  # Plot points\n",
    "lines(cubsplxy, lwd=2, col='red')  # Plot the spline fit\n",
    "knotx <- cubsplxy$fit$knot*cubsplxy$fit$range + cubsplxy$fit$min   # Find and plot the spline knots\n",
    "rug(knotx,col='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COnstrained B-Splines Nonparametric Regression Quantiles\n",
    "# Bartels, R. and Conn A. (1980) Linearly Constrained Discrete L_1 Problems, ACM Transaction on Mathematical Software 6, 594Ã¢â‚¬â€œ608.\n",
    "# Ng, P. (1996) An Algorithm for Quantile Smoothing Splines, Computational Statistics & Data Analysis 22, 99Ã¢â‚¬â€œ118.\n",
    "# He, X. and Ng, P. (1999) COBS: Qualitatively Constrained Smoothing via Linear Programming; Computational Statistics 14, 315Ã¢â‚¬â€œ337.\n",
    "# Ng, P. and Maechler, M. (2007) A Fast and Efficient Implementation of Qualitatively Constrained Quantile Smoothing Splines, Statistical Modelling 7(4), 315-328.\n",
    "\n",
    "if(!require(\"cobs\", quietly=T)) {\n",
    "  install.packages(\"cobs\", repos=\"https://cloud.r-project.org\", dependencies=TRUE)\n",
    "}; library(\"cobs\")\n",
    "plot(xy, pch=20, cex=0.5, xlab='log(Xvar)', ylab='log(Yvar)', \n",
    "\tmain='Spline quartile fit')  # Plot points\n",
    "lines(predict(cobs(x,y, ic='BIC', tau=0.25)), col='red', lw=2, lty=2)\n",
    "lines(predict(cobs(x,y, ic='BIC', tau=0.50)), col='red', lw=2)\n",
    "lines(predict(cobs(x,y, ic='BIC', tau=0.75)), col='red', lw=2, lty=2)\n",
    "rug(cobs(x,y, ic='BIC', tau=0.50)$knots, lwd=2, col=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Four well-established bivariate semi-parametric local regression estimators\n",
    "\n",
    "1. LOESS, 'LOcal regrESSion' in base-R, widely used (0.3M Google hits). Local polynomial regression with robust treatment of outliers.  Description in [Wikipedia](https://en.wikipedia.org/wiki/Local_regression).   Presented in the book W. S. Cleveland, `Visualizing Data', Hobart Press 1993\n",
    "\n",
    "2. Nonparametric regression with bootstrap errors in CRAN package 'np'. See Hayfield, T. & Racine, J. S. Nonparametric Econometrics: The np package, [J. Statist. Software, 27(5), 2008](http://www.jstatsoft.org/v27/i05/).\n",
    "\n",
    "3. Locfit in CRAN package 'locfit', widely used (>200 downloads/day).  Local kernel regression methods including heteroscedastic weighting (unequal error bars), censoring (upper limits), and outliers.  Presented in the book Loader, C. (1999) _Local Regression and Likelihood_ Springer, New York.\n",
    "\n",
    "4. Gaussian Process regression, commonly known as `kriging`. Response variable errors and independent variable covariance are assumed to be normal.  Maximum likelihood & Bayesian estimation.  Description in book  Rasmussen & Williams, Gaussian Processes for Machine Learning, 2006.   Other Gaussian processes regression codes are given in CRAN packages\n",
    "'mlegp' (Maximum Likelihood Estimates of Gaussian Processes) and 'gptk'\n",
    "(Gaussian Processes tool-kit). See also the tutorial [here](http://www.r-bloggers.com/gaussian-process-regression-with-r/). \n",
    "\n",
    "Finally, we plot all of these nonparametric regressions on the same plot.  We find that, in this case, they are quite compatible with each other.\n",
    "\n",
    "> **Exercise 3:**  Choose one of these methods, read the help file, and play around with the input parameters.  Note that sometimes multiple functions are involved, such as _loess.control_ associated with _loess_, and _locfit.raw_ and _lp_ associated with _locfit_.\n",
    "\n",
    "> **Exercise 4:** Perhaps the most capable of these packages, with strong foundations in likelihood theory, is Clive Loader's _locfit_ written in the early years of R.   It incorporates complexities such as survival analysis for nondetections, robust regression for non-Gaussian scatter, and heteroscedasticity for measurement error weighting.  To exercise _locfit_ well, it is necessary to get a hold of the 1999 Springer book by Loader, which unfortunately is not available in electronic form.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOESS,  W. S. Cleveland, `Visualizing Data', Hobart Press 1993\n",
    "\n",
    "par(mfrow=c(1,1))\n",
    "sortx <- x[order(x)] ; sorty <- y[order(x)]\n",
    "local_fit <- loess(sorty ~ sortx, span=0.25, data.frame(x=x,y=y))\t\n",
    "summary(local_fit)\n",
    "plot(x,y,pch=20, cex=0.5, main='LOESS')\n",
    "lines(sortx, predict(local_fit), lwd=2, col=2)\n",
    "\n",
    "# Save evenly-spaced LOESS fit to a file \n",
    "\n",
    "x_seq <- seq(0.0, 3.0, by=0.03) \n",
    "loc_dat <- predict(local_fit, newdata=x_seq)\n",
    "write(rbind(x_seq,loc_dat), sep=' ', ncol=2, file='localfit.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Nonparametric regression with bootstrap errors\n",
    "# Hayfield, T. & Racine, J. S. Nonparametric Econometrics: The np package, \n",
    "# J. Statist. Software, 27(5), 2008   http://www.jstatsoft.org/v27/i05/\n",
    "\n",
    "if(!require(\"np\", quietly=T)) {\n",
    "  install.packages(\"np\", repos=\"https://cloud.r-project.org\", dependencies=TRUE)\n",
    "}; library(\"np\")\n",
    "bw.NW <- npregbw(x, y, regtype='lc', bwtype='fixed')\n",
    "# help(npregbw)\n",
    "# help(npplot)\n",
    "# str(bw.NW)\n",
    "# bw.NW$bw <- 0.5 * bw.NW$bw\n",
    "# cat('New bandwidth for np local regression = ', bw.NW$bw)\n",
    "npplot(bws=bw.NW, ylim=c(0.0,2.5), plot.errors.method=\"bootstrap\", \n",
    "    plot.errors.bar='I', plot.errors.type='quantiles', main='NP with bootstrap CI') \n",
    "points(x, y, pch=20, cex=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locfit: local kernel regression methods including heteroscedastic weighting\n",
    "# (unequal error bars), censoring (upper limits), and outliers.\n",
    "# Loader, C. (1999). Local Regression and Likelihood. Springer, New York.\n",
    "# >200 downloads/day\n",
    "\n",
    "if(!require(\"locfit\", quietly=T)) {\n",
    "  install.packages(\"locfit\", repos=\"https://cloud.r-project.org\", dependencies=TRUE)\n",
    "}; library(\"locfit\")\n",
    "locfit_model <- locfit(y~lp(x, nn=0.7))\n",
    "plot(locfit_model, band='local', ylim=c(0,2.5), col=2, main='locfit bandwidth=0.7')  ;  points(xy, pch=20, cex=0.5)\n",
    "locfit_model <- locfit(y~lp(x, nn=0.3))\n",
    "plot(locfit_model, band='local', ylim=c(0,2.5), col=3, main='locfit bandwidth=0.3')  ;  points(xy, pch=20, cex=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian process regression (more commonly known as `kriging')\n",
    "# Response variable errors and independent variable covariance assumed to be normal\n",
    "# Maximum likelihood & Bayesian estimation\n",
    "# Rasmussen & Williams, Gaussian Processes for Machine Learning, 2006\n",
    "\n",
    "if(!require(\"kernlab\", quietly=T)) {\n",
    "  install.packages(\"kernlab\", repos=\"https://cloud.r-project.org\", dependencies=TRUE)\n",
    "}; library(\"kernlab\")\n",
    "gpreg <- gausspr(x, y, variance.model=T, cross=10, kerne='polydot', kpar=list(5))\n",
    "gpreg\n",
    "xtest <- seq(from=min(x), to=max(x), length.out=200)\n",
    "plot(x, y, pch=20, cex=0.5, main='GP regression')\n",
    "lines(xtest, predict(gpreg, xtest), col='red3', lwd=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot several smooth density estimators on a single graph\n",
    "\n",
    "npplot(bws=bw.NW, ylim=c(0.5,1.5), plot.errors.method=\"bootstrap\",\n",
    "plot.errors.bar='I', plot.errors.type='quantiles') \t# Nonparametric regression w/ bootstrap errors\n",
    "points(x, y, pch=20, cex=0.5)\n",
    "lines(xtest, predict(gpreg, xtest), col='red3', lwd=3)  #  Gaussian Processes regression\n",
    "lines(predict(cobs(x,y, ic='BIC', tau=0.25)), col='blue3')\n",
    "lines(predict(cobs(x,y, ic='BIC', tau=0.50)), col='blue3')\n",
    "lines(predict(cobs(x,y, ic='BIC', tau=0.75)), col='blue3')\n",
    "lines(sortx, predict(local_fit), lwd=2, col='green') # LOESS\n",
    "locfit_values <- predict(locfit_model, seq(0,3,length.out=100))\n",
    "lines(seq(0,3,length.out=100), locfit_values, lwd=2, col=\"chocolate\")  # locfit\n",
    "legend('topleft', lty=1, lwd=2, c(\"NP reg w/ bootstrap\",'Gauss Proc reg', 'Quantile reg', 'LOESS', 'locfit'), col=c('black', 'red3', 'blue3', 'green', 'chocolate'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R (system-wide)",
   "language": "r",
   "metadata": {
    "cocalc": {
     "description": "R statistical programming language",
     "priority": 10,
     "url": "https://www.r-project.org/"
    }
   },
   "name": "ir",
   "resource_dir": "/ext/jupyter/kernels/ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
