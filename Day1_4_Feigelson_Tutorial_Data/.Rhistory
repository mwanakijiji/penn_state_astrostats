plot(NGC4472.fit$model$radius, NGC4472.fit$model$surf_mag, pch=20,
xlab="r  (arcsec)", ylab=expression(mu ~~ (mag/sq.arcsec)), ylim=c(16,28),
cex.lab=1.5, cex.axis=1.5)
lines(NGC4472.fit$model$radius, fitted(NGC4472.fit))
lines(NGC4472.fit$model$radius, fitted(NGC4472.fit), col='red')
formula(NGC4472.fit)    # formula used
coef(NGC4472.fit)       # best-fit parameters
vcov(NGC4472.fit)       # best-fit parameter covariance matrix
logLik(NGC4472.fit)     # log-likelihood of best fit
confint(NGC4472.fit)    # 95% confidence intervals
profile(NGC4472.fit)    # profiles (cuts) around the best fit (unfortunately the console output is verbose here)
fitted(NGC4472.fit)     # fitted values
residuals(NGC4472.fit)  # residuals from the fitted values
plot(NGC4472.fit$model$radius,residuals(NGC4472.fit), xlab="r (arcsec)",
ylab="Residuals", pch=20, cex.lab=1.5, cex.axis=1.5)
lines(supsmu(NGC4472.fit$model$radius, residuals(NGC4472.fit), span=0.05),
lwd=2)
lines(NGC4472.fit$model$radius, fitted(NGC4472.fit), lw=2, col='red')
plot(NGC4472.fit$model$radius, NGC4472.fit$model$surf_mag, pch=20,
xlab="r  (arcsec)", ylab=expression(mu ~~ (mag/sq.arcsec)), ylim=c(16,28),
cex.lab=1.5, cex.axis=1.5)
lines(NGC4472.fit$model$radius, fitted(NGC4472.fit), lw=2, col='red')
formula(NGC4472.fit)    # formula used
coef(NGC4472.fit)       # best-fit parameters
vcov(NGC4472.fit)       # best-fit parameter covariance matrix
logLik(NGC4472.fit)     # log-likelihood of best fit
confint(NGC4472.fit)    # 95% confidence intervals
profile(NGC4472.fit)    # profiles (cuts) around the best fit (unfortunately the console output is verbose here)
fitted(NGC4472.fit)     # fitted values
residuals(NGC4472.fit)  # residuals from the fitted values
plot(NGC4472.fit$model$radius,residuals(NGC4472.fit), xlab="r (arcsec)",
ylab="Residuals", pch=20, cex.lab=1.5, cex.axis=1.5)
lines(supsmu(NGC4472.fit$model$radius, residuals(NGC4472.fit), span=0.05),
lwd=2, 'red')
plot(NGC4472.fit$model$radius,residuals(NGC4472.fit), xlab="r (arcsec)",
ylab="Residuals", pch=20, cex.lab=1.5, cex.axis=1.5)
lines(supsmu(NGC4472.fit$model$radius, residuals(NGC4472.fit), span=0.05),
lwd=2, 'red')
par(mai=c(1,1,0.8,0.44))   # improve left-hand margin
plot(NGC4472.fit$model$radius, NGC4472.fit$model$surf_mag, pch=20,
xlab="r  (arcsec)", ylab=expression(mu ~~ (mag/sq.arcsec)), ylim=c(16,28),
cex.lab=1.5, cex.axis=1.5)
lines(NGC4472.fit$model$radius, fitted(NGC4472.fit), lw=2, col='red')
plot(NGC4472.fit$model$radius,residuals(NGC4472.fit), xlab="r (arcsec)",
ylab="Residuals", pch=20, cex.lab=1.5, cex.axis=1.5)
lines(supsmu(NGC4472.fit$model$radius, residuals(NGC4472.fit), span=0.05),
lwd=2, 'red')
formula(NGC4472.fit)    # formula used
coef(NGC4472.fit)       # best-fit parameters
vcov(NGC4472.fit)       # best-fit parameter covariance matrix
logLik(NGC4472.fit)     # log-likelihood of best fit
confint(NGC4472.fit)    # 95% confidence intervals
profile(NGC4472.fit)    # profiles (cuts) around the best fit (unfortunately the console output is verbose here)
fitted(NGC4472.fit)     # fitted values
residuals(NGC4472.fit)  # residuals from the fitted values
plot(NGC4472.fit$model$radius,residuals(NGC4472.fit), xlab="r (arcsec)",
ylab="Residuals", pch=20, cex.lab=1.5, cex.axis=1.5)
lines(supsmu(NGC4472.fit$model$radius, residuals(NGC4472.fit), span=0.05),
lwd=2, 'red')
NGC4472.fit <-  nls(surf_mag ~ -2.5*log10(I.e * 10^(-(0.868*n-0.142)*
((radius/r.e)^{1/n}-1))) + 26, data=list(NGC4472), start=list(I.e=20.,
r.e=120.,n=4.), model=T, trace=T)
summary(NGC4472.fit)
logLik(NGC4472.fit)
par(mai=c(1,1,0.8,0.44))   # improve left-hand margin
plot(NGC4472.fit$model$radius, NGC4472.fit$model$surf_mag, pch=20,
xlab="r  (arcsec)", ylab=expression(mu ~~ (mag/sq.arcsec)), ylim=c(16,28),
cex.lab=1.5, cex.axis=1.5)
lines(NGC4472.fit$model$radius, fitted(NGC4472.fit), lw=2, col='red')
formula(NGC4472.fit)    # formula used
coef(NGC4472.fit)       # best-fit parameters
vcov(NGC4472.fit)       # best-fit parameter covariance matrix
logLik(NGC4472.fit)     # log-likelihood of best fit
confint(NGC4472.fit)    # 95% confidence intervals
profile(NGC4472.fit)    # profiles (cuts) around the best fit (unfortunately the console output is verbose here)
fitted(NGC4472.fit)     # fitted values
residuals(NGC4472.fit)  # residuals from the fitted values
plot(NGC4472.fit$model$radius,residuals(NGC4472.fit), xlab="r (arcsec)",
ylab="Residuals", pch=20, cex.lab=1.5, cex.axis=1.5)
lines(supsmu(NGC4472.fit$model$radius, residuals(NGC4472.fit), span=0.05),
lwd=2, 'red')
supsmu(NGC4472.fit$model$radius, residuals(NGC4472.fit)
supsmu(NGC4472.fit$model$radius, residuals(NGC4472.fit), span=0.05)
dim(supsmu(NGC4472.fit$model$radius, residuals(NGC4472.fit), span=0.05))
lines(supsmu(NGC4472.fit$model$radius, residuals(NGC4472.fit), span=0.05),
lwd=2, 'red')
dim(supsmu(NGC4472.fit$model$radius, residuals(NGC4472.fit), span=0.05)$x)
dim(supsmu(NGC4472.fit$model$radius, residuals(NGC4472.fit), span=0.05)$y)
a <- supsmu(NGC4472.fit$model$radius, residuals(NGC4472.fit), span=0.05)
a
a$x
a$y
a
lines(a)
lines(supsmu(NGC4472.fit$model$radius, residuals(NGC4472.fit), span=0.05),
lwd=2, 'red')
lines(supsmu(NGC4472.fit$model$radius, residuals(NGC4472.fit), span=0.05),
lwd=2, col='red')
qqnorm(residuals(NGC4472.fit) / summary(NGC4472.fit)$sigma)
abline(a=0,b=1)
shapiro.test(residuals(NGC4472.fit) / summary(NGC4472.fit)$sigma)
acf(residuals(NGC4472.fit))
set.seed(1)
x <- sample(seq(0.01, 3, length.out=500))
y <- 0.5*x + 0.3^(x^2) + rnorm(500, mean=0, sd=(0.05*(1+x^2)))
xy <- cbind(x, y)
plot(xy, pch=20)
cubsplxy <- smooth.spline(log10(xy))
plot(log10(xy), pch=20, cex=0.5, ylim=c(-0.7, 0.4), xlab='log(Xvar)',
ylab='log(Yvar)', main='Cubic spline fit')  # Plot points
lines(cubsplxy, lwd=2, col='darkgreen')  # Plot the spline fit
knotx <- cubsplxy$fit$knot*cubsplxy$fit$range + cubsplxy$fit$min   # Find and plot the spline knots
rug(knotx,col='darkgreen')
#install.packages('cobs', repos="https://cloud.r-project.org", dependencies=TRUE)
if(!require("cobs", quietly=T)) {
install.packages("cobs", repos="https://cloud.r-project.org", dependencies=TRUE)
}; library("cobs")
plot(log10(xy), pch=20, cex=0.5, ylim=c(-0.7, 0.4), xlab='log(Xvar)',
ylab='log(Yvar)', main='Spline quartile fit')  # Plot points
cobsxy50 <- cobs(log10(x), log10(y), ic='BIC', tau=0.5)  #  Median regression fit
lines(sort(cobsxy50$x),cobsxy50$fitted[order(cobsxy50$x)], lwd=2, col=2)
cobsxy25 <- cobs(log10(x), log10(y), ic='BIC', tau=0.25)
lines(sort(cobsxy25$x),cobsxy25$fitted[order(cobsxy25$x)], lwd=1, col=2)
cobsxy75 <- cobs(log10(x), log10(y), ic='BIC', tau=0.75)
lines(sort(cobsxy75$x),cobsxy75$fitted[order(cobsxy75$x)], lwd=1, col=2)
plot(log10(xy), pch=20, cex=0.5, ylim=c(-0.7, 0.4), xlab='log(Xvar)',
ylab='log(Yvar)', main='Spline quartile fit')  # Plot points
cobsxy50 <- cobs(log10(x), log10(y), ic='BIC', tau=0.5)  #  Median regression fit
lines(sort(cobsxy50$x),cobsxy50$fitted[order(cobsxy50$x)], lwd=2, col=2)
cobsxy25 <- cobs(log10(x), log10(y), ic='BIC', tau=0.25)
lines(sort(cobsxy25$x),cobsxy25$fitted[order(cobsxy25$x)], lwd=1, col=2)
cobsxy75 <- cobs(log10(x), log10(y), ic='BIC', tau=0.75)
lines(sort(cobsxy75$x),cobsxy75$fitted[order(cobsxy75$x)], lwd=1, col=2)
plot(log10(xy), pch=20, cex=0.5, ylim=c(-0.7, 0.4), xlab='log(Xvar)',
ylab='log(Yvar)', main='Spline quartile fit')  # Plot points
cobsxy50 <- cobs(log10(x), log10(y), ic='BIC', tau=0.5)  #  Median regression fit
lines(sort(cobsxy50$x),cobsxy50$fitted[order(cobsxy50$x)], lwd=2, col=2)
cobsxy25 <- cobs(log10(x), log10(y), ic='BIC', tau=0.25)
lines(sort(cobsxy25$x),cobsxy25$fitted[order(cobsxy25$x)], lwd=1, col=2)
cobsxy75 <- cobs(log10(x), log10(y), ic='BIC', tau=0.75)
lines(sort(cobsxy75$x),cobsxy75$fitted[order(cobsxy75$x)], lwd=1, col=2)
rug(cobsxy50$knots, lwd=2, col=2)
par(mfrow=c(1,1))
sortx <- x[order(x)] ; sorty <- y[order(x)]
local_fit <- loess(sorty ~ sortx, span=0.35, data.frame(x=x,y=y))
summary(local_fit)
plot(x,y,pch=20, cex=0.5, main='LOESS')
lines(sortx, predict(local_fit), lwd=2, col=2)
if(!require("kernlab", quietly=T)) {
install.packages("kernlab", repos="https://cloud.r-project.org", dependencies=TRUE)
}; library("kernlab")
gpreg <- gausspr(x, y, variance.model=T, cross=10, kerne='polydot', kpar=list(5))
xtest <- seq(from=min(x), to=max(x), length.out=200)
plot(x, y, pch=20, cex=0.5, main='GP regression')
lines(xtest, predict(gpreg, xtest), col='darkred', lwd=2)
?bkde2D
?require
if(!require("e1071", quietly=T)) {
install.packages("e1071", repos="https://cloud.r-project.org", dependencies=TRUE)
}; library("e1071")
if(!require("randomForest", quietly=T)) {
install.packages("randomForest", repos="https://cloud.r-project.org", dependencies=TRUE)
}; library("randomForest")
if(!require("class", quietly=T)) {
install.packages("class", repos="https://cloud.r-project.org", dependencies=TRUE)
}; library("class")
if(!require("fpc", quietly=T)) {
install.packages("fpc", repos="https://cloud.r-project.org", dependencies=TRUE)
}; library("fpc")
COMBO_loz=read.table('COMBO17_lowz.dat', header=T, fill=T)
dim(COMBO_loz)
names(COMBO_loz)
names(COMBO_loz) <- c('MB', 'M280-MB')  ; names(COMBO_loz)
plot(COMBO_loz, pch=20, cex=0.5, xlim=c(-22,-7), ylim=c(-2,2.5),
xlab=expression(M[B]~~(mag)), ylab=expression(M[280] - M[B]~~(mag)),
main='')
library(MASS)
COMBO_loz_sm <- kde2d(COMBO_loz[,1], COMBO_loz[,2], h=c(1.6,0.4),
lims = c(-22,-7,-2,2.5), n=500)
image(COMBO_loz_sm, col=grey(13:0/15), xlab=expression(M[B]~~(mag)),
ylab=expression(M[280] - M[B]~~(mag)), xlim=c(-22,-7), ylim=c(-2,2.5),
xaxp=c(-20,-10,2))
text(-16.5, -1, "Blue cloud", col='darkblue', pos=4, cex=0.8)
text(-17,-0.7, 'Green valley', col='darkgreen', pos=4, cex=0.8)
text(-13, -0.2, 'Red sequence', col='red', pos=4, cex=0.8)
text(-18.5, 1.7, 'Bright cluster galaxies', col='deeppink3', pos=4, cex=0.8)
dev.off()
Mag_std <- scale(COMBO_loz[,1])
Color_std <- scale(COMBO_loz[,2])
COMBO_std <- cbind(Mag_std,Color_std)
COMBO_dist <- dist(COMBO_std)
COMBO_hc <- hclust(COMBO_dist, method='ward.D')
plot(COMBO_hc, label=F)
COMBO_hc5a <- rect.hclust(COMBO_hc, k=5, border='red')
COMBO_hc5b <- cutree(COMBO_hc, k=5)
plot(COMBO_loz, pch=(COMBO_hc5b+18), cex=0.7, xlab=expression(M[B]~~(mag)),
ylab=expression(M[280] - M[B]~~(mag)), main='')
# install.packages('fpc')
library(fpc)
COMBO_dbs <-  dbscan(COMBO_std, eps=0.1, MinPts=5, method='raw')
print.dbscan(COMBO_dbs) ; COMBO_dbs$cluster
plot(COMBO_loz[COMBO_dbs$cluster==0,], pch=20, cex=0.7, xlab='M_B (mag)',
ylab='M_280 - M_B (mag)')
points(COMBO_loz[COMBO_dbs$cluster==2,], pch=2, cex=1.0, col='blue2')
points(COMBO_loz[COMBO_dbs$cluster==1 | COMBO_dbs$cluster==3,], pch=1, cex=1.0, col='orangered3')
library(dbscan)
SDSS <- read.csv('SDSS_test.csv', h=T)
dim(SDSS) ; summary(SDSS)
SDSS_test <- data.frame(  # create data frame of SDSS colors
u_g = SDSS$u_mag - SDSS$g_mag,
g_r = SDSS$g_mag - SDSS$r_mag,
r_i = SDSS$r_mag - SDSS$i_mag,
i_z = SDSS$i_mag - SDSS$z_mag
)
names(SDSS_test) <- c('u_g', 'g_r', 'r_i', 'i_z')
str(SDSS_test)
par(mfrow=c(1,3))  # plot test set in black because labels are not yet established
plot(SDSS_test[,1], SDSS_test[,2], xlim=c(-0.7,3), ylim=c(-0.7,1.8),pch=20,
cex=0.6, cex.lab=1.5, cex.axis=1.5, main='Test dataset', xlab='u-g (mag)', ylab='g-r (mag)')
plot(SDSS_test[,2], SDSS_test[,3], xlim=c(-0.7,1.8), ylim=c(-0.7,1.8), pch=20,
cex=0.6, cex.lab=1.5, cex.axis=1.5, main='', xlab='g-r (mag)', ylab='r-i (mag)')
plot(SDSS_test[,3], SDSS_test[,4], xlim=c(-0.7,1.8), ylim=c(-1.1,1.3), pch=20,
cex=0.6, cex.lab=1.5, cex.axis=1.5, main='', xlab='r-i (mag)', ylab='i-z (mag)')
par(mfrow=c(1,1))
qso1 <- read.table('SDSS_QSO.dat', h=T)
dim(qso1) ; summary(qso1)
bad_phot_qso <- which(qso1[,c(3,5,7,9,11)] > 21.0 | qso1[,3]==0)  # identify bad photometry
qso2 <- qso1[1:2000,-bad_phot_qso,]  # remove bad photometry
qso3 <- cbind((qso2[,3]-qso2[,5]), (qso2[,5]-qso2[,7]), (qso2[,7]-qso2[,9]), (qso2[,9]-qso2[,11])) # cbind concatenates colums
qso_train <- data.frame(cbind(qso3, rep(1, length(qso3[,1]))))
names(qso_train) <- c('u_g', 'g_r', 'r_i', 'i_z', 'Class')
dim(qso_train) ; summary(qso_train)
temp2 <- read.csv('SDSS_stars.csv', h=T)
dim(temp2) ; summary(temp2)
star <- cbind((temp2[,1]-temp2[,2]), (temp2[,2]-temp2[,3]), (temp2[,3]-temp2[,4]),
(temp2[,4]-temp2[,5]))
star_train <- data.frame(cbind(star, rep(2, length(star[,1]))))
names(star_train) <- c('u_g','g_r','r_i','i_z','Class')
dim(star_train)
temp3 <- read.csv('SDSS_wd.csv', h=T)
dim(temp3) ; summary(temp3)
temp3 <- na.omit(temp3)  # remove objects with missing data
wd <- cbind((temp3[1:2000,2]-temp3[1:2000,3]), (temp3[1:2000,3]-temp3[1:2000,4]),
(temp3[1:2000,4]-temp3[1:2000,5]), (temp3[1:2000,5]-temp3[1:2000,6]))
wd_train <- data.frame(cbind(wd, rep(3, length(wd[,1]))))
names(wd_train) <- c('u_g', 'g_r', 'r_i', 'i_z', 'Class')
dim(wd_train)
SDSS_train <- data.frame(rbind(qso_train, star_train, wd_train))  # rbind concatenates rows
names(SDSS_train) <- c('u_g', 'g_r', 'r_i', 'i_z', 'Class')
str(SDSS_train)
par(mfrow=c(1,3))  # plot training set in colors representing labeled classes
plot(SDSS_train[,1], SDSS_train[,2], xlim=c(-0.7,3), ylim=c(-0.7,1.8), pch=20,
col=SDSS_train[,5], cex=0.6, cex.lab=1.6, cex.axis=1.6, main='Training dataset', xlab='u-g (mag)',
ylab='g-r (mag)')
legend(-0.5, 1.7, c('QSO','MS + RG','WD'), pch=20, col=c('black','red','green'),
cex=0.8)
plot(SDSS_train[,2], SDSS_train[,3], xlim=c(-0.7,1.8), ylim=c(-0.7,1.8), pch=20,
col=SDSS_train[,5], cex=0.6, cex.lab=1.6, cex.axis=1.6, main='', xlab='g-r (mag)',
ylab='r-i (mag)')
plot(SDSS_train[,3], SDSS_train[,4], xlim=c(-0.7,1.8), ylim=c(-1.1,1.3), pch=20,
col=SDSS_train[,5], cex=0.6, cex.lab=1.6, cex.axis=1.6, main='', xlab='r-i (mag)',
ylab='i-z (mag)')
par(mfrow=c(1,1))
class_eval <- function(pred, act, plot=TRUE, ...){
iact <- as.integer(act)
ipred <- as.integer(pred)
acc <- sum(ipred==iact)/length(iact)  # accuracy
if (isTRUE(plot)){
plot(jitter(ipred), jitter(iact), pch=20, cex=0.5, xlab='Predicted Class', ylab='True class',lab=c(3,3,1), ...)
mtext(paste("Accuracy =", round(acc, 3)))
}
return(list("Confusion Table"=table("True Class"=iact, "Predicted Class"=ipred), Accuracy=acc))
}
SDSS_train_full <- SDSS_train
set.seed(456)
val_set <- sample(nrow(SDSS_train), round(nrow(SDSS_train)*0.2))
SDSS_val <- SDSS_train_full[val_set,]
SDSS_train <- SDSS_train_full[-val_set,]
set.seed(123)
SDSS_rand_train_pred <- sample(1:3, nrow(SDSS_train), replace=T)
par(mfcol=c(1, 1))
class_eval(SDSS_rand_train_pred, SDSS_train$Class, main="Random Assignment")
SDSS.kmean <- kmeans(SDSS_test,6)
print(SDSS.kmean$centers)
plot(SDSS_test[,1], SDSS_test[,2], pch=20, cex=0.3, col=gray(SDSS.kmean$cluster/7),
xlab='u-g (mag)', ylab='g-r (mag)', xlim=c(-0.5,3), ylim=c(-0.6,1.5))
library(MASS)
SDSS_lda <- lda(SDSS_train[,1:4], as.factor(SDSS_train[,5]))
SDSS_lda_train_pred <- predict(SDSS_lda)$class
SDSS_lda_val_pred <- predict(SDSS_lda, SDSS_val[,1:4])$class
SDSS_lda_test_pred <- predict(SDSS_lda, SDSS_test[,1:4])$class
plot(SDSS_val[,1],SDSS_val[,2], xlim=c(-0.7,3), ylim=c(-0.7,1.8), pch=20,
col=SDSS_lda_val_pred, cex=0.5, main='', xlab='u-g (mag)', ylab='g-r (mag)')
class_eval(SDSS_lda_val_pred, SDSS_val$Class, main="LDA Classification")
library(class)
SDSS_knn_test_pred <- knn(SDSS_train[,1:4], SDSS_test, as.factor(SDSS_train[,5]), k=5, prob=T)
SDSS_knn_val_pred <- knn(SDSS_train[,1:4], SDSS_val[,1:4], as.factor(SDSS_train[,5]), k=5, prob=T)
plot(SDSS_val[,1], SDSS_val[,2], xlim=c(-0.7,3), ylim=c(-0.7,1.8), pch=20,
col=SDSS_knn_val_pred, cex=0.5, main='', xlab='u-g (mag)', ylab='g-r (mag)')
class_eval(SDSS_knn_val_pred, SDSS_val$Class, main="kNN Classification")
library(nnet)
SDSS_nnet <- nnet(as.factor(Class) ~ u_g + g_r + r_i + i_z, SDSS_train,size=5)
SDSS_nnet_train_pred <- predict(SDSS_nnet, type="class")
SDSS_nnet_val_pred <- predict(SDSS_nnet, SDSS_val, type="class")
SDSS_nnet_test_pred <- predict(SDSS_nnet, SDSS_test, type="class")
plot(SDSS_val[,1], SDSS_val[,2], xlim=c(-0.7,3), ylim=c(-0.7,1.8), pch=20,
col=SDSS_nnet_val_pred, cex=0.5, main='', xlab='u-g (mag)', ylab='g-r (mag)')
class_eval(SDSS_nnet_val_pred, SDSS_val$Class, main="Neural Net Classification")
library(rpart)
SDSS_rpart <- rpart(SDSS_train[,5] ~., data=SDSS_train[,1:4], method="class")
summary(SDSS_rpart)
str(SDSS_rpart)
SDSS_rpart_train_pred <- predict(SDSS_rpart, type="class")
SDSS_rpart_val_pred <- predict(SDSS_rpart, SDSS_val, type="class")
SDSS_rpart_test_pred <- predict(SDSS_rpart, SDSS_test, type="class")
plot(SDSS_val[,1], SDSS_val[,2], xlim=c(-0.7,3), ylim=c(-0.7,1.8), pch=20,
col=SDSS_rpart_val_pred, cex=0.5,
main='', xlab='u-g (mag)', ylab='g-r (mag)')
class_eval(SDSS_rpart_val_pred, SDSS_val$Class, main="Tree Classification")
plot(SDSS_rpart, branch=0.5, margin=0.05)
text(SDSS_rpart, digits=3, use.n=T, cex=0.8)
plotcp(SDSS_rpart, lwd=2, cex.axis=1.3, cex.lab=1.3)
library(randomForest)
library(e1071)
SDSS_svm <- svm((SDSS_train[,5]) ~.,data=SDSS_train[,1:4],cost=100, gamma=1)
SDSS_svm <- svm(as.factor(SDSS_train[,5]) ~.,data=SDSS_train[,1:4],cost=100, gamma=1)
summary(SDSS_svm)
SDSS_svm_train_pred <- predict(SDSS_svm)
SDSS_svm_val_pred <- predict(SDSS_svm, SDSS_val)
SDSS_svm_test_pred <- predict(SDSS_svm, SDSS_test)
plot(SDSS_test[,1], SDSS_test[,2], xlim=c(-0.7,3), ylim=c(-0.7,1.8), pch=20,
col=round(as.numeric(SDSS_svm_test_pred)), cex=0.5, main='',
xlab='u-g (mag)', ylab='g-r (mag)')
class_eval(SDSS_svm_val_pred, SDSS_val$Class, main="Random Forest Classification")
par(mfrow=c(1,3))
plot(SDSS_test[,1], SDSS_test[,2], xlim=c(-0.7,3), col=round(as.numeric(SDSS_svm_test_pred)),
ylim=c(-0.7,1.8), pch=20, cex=0.5, main='Support Vector Machine', xlab='u-g (mag)',ylab='g-r (mag)')
plot(SDSS_test[,2], SDSS_test[,3], xlim=c(-0.7,1.8), col=round(as.numeric(SDSS_svm_test_pred)),
ylim=c(-0.7,1.8), pch=20, cex=0.5, main='Classification of', xlab='g-r (mag)',ylab='r-i (mag)')
plot(SDSS_test[,3], SDSS_test[,4], xlim=c(-0.7,1.8), col=round(as.numeric(SDSS_svm_test_pred)),
ylim=c(-1.1,1.3), pch=20, cex=0.5, main='SDSS Test Dataset', xlab='r-i (mag)',ylab='i-z (mag)')
par(mfrow=c(1,1))
SDSS_test_svm_out <- cbind(SDSS[,6], SDSS[,7], SDSS_test, round(as.numeric(SDSS_svm_test_pred)))
names(SDSS_test_svm_out)[c(1,2,7)] <- c('R.A.', 'Dec', 'SVM Class')
download.file(url = "https://git.psu.edu/stat/astro/datasets/-/raw/master/COMBO17_lowz.dat", destfile = "COMBO17_lowz.dat")
GX.dat <- scan("GX.dat")
getwd()
str(GX.dat)
summary(GX.dat)
GX.time <- seq(from=0, to=512, length.out=length(GX.dat))
GX.ts <-  ts(GX.dat, GX.time) ; GX.ts.offset <- ts(GX.dat-30, GX.time)
str(GX.ts)
plot.ts(GX.ts, ylab='GX 5-1 counts', xlab='Time (x 1/128 sec)',
cex.lab=1.3, cex.axis=1.3, lwd=0.5)
hist(GX.dat, breaks=100, xlim=c(40,100), ylim=c(0,3500), xlab='GX 5-1 counts',
font=2, font.lab=2, main='')
curve(dnorm(x,mean=mean(GX.dat), sd=sqrt(mean(GX.dat)))*65536, lwd=3, add=T)
sd(GX.dat) / sqrt(mean(GX.dat))  # counts are 1.24 x overdispersed compared to Gaussian noise
plot.ts(GX.ts[1:6000], ylab='GX 5-1 counts', xlab='Time (x 1/128 sec)',
cex.lab=1.3, cex.axis=1.3)  # Close-up view of 10% of the data
plot(GX.time,GX.dat, ylim=c(-10,115), xlab='Time (sec)', ylab='GX 5-1 counts',
cex.lab=1.3, cex.axis=1.3, type='n')  # set up plot window but don't show any data
lines(ksmooth(GX.time, GX.dat+30, 'normal', bandwidth=7), lwd=2)
text(450, 110, 'Normal kernel')  # Gaussian kernel density estimator with 7 bin FWHM bandwidth
lines(filter(GX.ts, sides=2, rep(1,7)/7), lwd=2)
text(450, 85, 'Moving average') # Moving average smoother with 7 bin bandwidth
lines(kernapply(GX.ts.offset, kernel('modified.daniell', 7)), lwd=2)
text(450, 50, 'Modified Daniell')  # Moving average smoother with 1/2-weight at the end values of the span
lines(supsmu(GX.time, GX.dat-60, span=0.01), lwd=2)
text(400, 20, "Friedman's super-smoother") # A smoother with adaptive bandwidth from Friedman (1984)
lines(lowess(GX.time, GX.dat-80, 0.02), lwd=2)
text(400, 0, 'LOWESS local regression') # Cleveland's (1979) robust local polynomial smoother
par(mfrow=c(1,2))
acf(GX.dat)
pacf(GX.dat)
par(mfrow=c(1,1))
par(mfrow=c(3,1))  ;  par(mar=c(5,4,1,2))
spec.pgram(GX.ts, log='no', main='')
spec.pgram(GX.ts, spans=50, log='no', main='', sub='')
spec.pgram(GX.ts, spans=200, taper=0.15, log='no', main='', sub='')
ARmod <- ar(GX.ts, method='ols')
print(ARmod)
ARspec <- spec.ar(GX.ts, plot=F)
GXspec <- spec.pgram(GX.ts, span=101, main='', sub='', lwd=2)
lines(ARspec$freq, ARspec$spec, col='green', lwd=2)
text(0.4,450, cex=2, paste0('AR(', ARmod$order, ')'))
acf(na.omit(ARmod$resid))
Box.test(ARmod$resid, type='Ljung')  # test for autocorrelation in AR residuals
library(goftest)
ad.test(na.omit(ARmod$resid))  # test for normality in AR residuals
plot(GX.time,GX.dat, ylim=c(-10,115), xlab='Time (sec)', ylab='GX 5-1 counts',
cex.lab=1.3, cex.axis=1.3, type='n')  # set up plot window but don't show any data
lines(ksmooth(GX.time, GX.dat+30, 'normal', bandwidth=7), lwd=2)
text(450, 110, 'Normal kernel')  # Gaussian kernel density estimator with 7 bin FWHM bandwidth
lines(filter(GX.ts, sides=2, rep(1,7)/7), lwd=2)
text(450, 85, 'Moving average') # Moving average smoother with 7 bin bandwidth
lines(kernapply(GX.ts.offset, kernel('modified.daniell', 7)), lwd=2)
text(450, 50, 'Modified Daniell')  # Moving average smoother with 1/2-weight at the end values of the span
lines(supsmu(GX.time, GX.dat-60, span=0.01), lwd=2)
text(400, 20, "Friedman's super-smoother") # A smoother with adaptive bandwidth from Friedman (1984)
lines(lowess(GX.time, GX.dat-80, 0.02), lwd=2)
text(400, 0, 'LOWESS local regression') # Cleveland's (1979) robust local polynomial smoother
par(mfrow=c(1,2))
acf(GX.dat)
pacf(GX.dat)
par(mfrow=c(1,1))
par(mfrow=c(3,1))  ;  par(mar=c(5,4,1,2))
spec.pgram(GX.ts, log='no', main='')
spec.pgram(GX.ts, spans=50, log='no', main='', sub='')
spec.pgram(GX.ts, spans=200, taper=0.15, log='no', main='', sub='')
if(!require("goftest", quietly=T)) {
install.packages("goftest", repos="https://cloud.r-project.org", dependencies=TRUE)
}; library(goftest)
ARmod <- ar(GX.ts, method='ols')
print(ARmod)
ARspec <- spec.ar(GX.ts, plot=F)
GXspec <- spec.pgram(GX.ts, span=101, main='', sub='', lwd=2)
lines(ARspec$freq, ARspec$spec, col='green', lwd=2)
text(0.4,450, cex=2, paste0('AR(', ARmod$order, ')'))
acf(na.omit(ARmod$resid))
Box.test(ARmod$resid, type='Ljung')  # test for autocorrelation in AR residuals
ad.test(na.omit(ARmod$resid))  # test for normality in AR residuals
if(!require("forecast", quietly=T)) {
install.packages("forecast", repos="https://cloud.r-project.org", dependencies=TRUE)
}; library(forecast)
ARspec <- spec.ar(GX.ts, plot=F)
GXspec <- spec.pgram(GX.ts, span=101, main='', sub='', lwd=2)
lines(ARspec$freq, ARspec$spec, col='green', lwd=2)
text(0.4,450, cex=2, paste0('AR(', ARmod$order, ')'))
par(mfrow=c(3,1))  ;  par(mar=c(5,4,1,2))
spec.pgram(GX.ts, log='no', main='')
spec.pgram(GX.ts, spans=50, log='no', main='', sub='')
spec.pgram(GX.ts, spans=200, taper=0.15, log='no', main='', sub='')
if(!require("goftest", quietly=T)) {
install.packages("goftest", repos="https://cloud.r-project.org", dependencies=TRUE)
}; library(goftest)
ARmod <- ar(GX.ts, method='ols')
print(ARmod)
ARspec <- spec.ar(GX.ts, plot=F)
GXspec <- spec.pgram(GX.ts, span=101, main='', sub='', lwd=2)
lines(ARspec$freq, ARspec$spec, col='green', lwd=2)
text(0.4,450, cex=2, paste0('AR(', ARmod$order, ')'))
acf(na.omit(ARmod$resid))
Box.test(ARmod$resid, type='Ljung')  # test for autocorrelation in AR residuals
ad.test(na.omit(ARmod$resid))  # test for normality in AR residuals
if(!require("forecast", quietly=T)) {
install.packages("forecast", repos="https://cloud.r-project.org", dependencies=TRUE)
}; library(forecast)
ARIMA_fit <- auto.arima(GX.ts)
summary(ARIMA_fit)
par(mfrow=c(2,1))  ;  par(mar=c(5,4,1,2))
arima_fit <- auto.arima(GX.ts, stepwise=FALSE, approximation=FALSE, max.p=3, max.q=3, max.d=1)
acf(arima_fit$residuals)
Box.test(arima_fit$residuals, type='Ljung-Box')
arfima_fit <- arfima(GX.ts)
summary(arfima_fit)
acf(arfima_fit$residuals)
Box.test(arfima_fit$residuals, type='Ljung-Box')
sd(arfima_fit$x) ; sd(arfima_fit$residuals)
Kepler1 <- read.table('Kepler1.dat')[[1]] # KIC 007596240
Kepler2 <- read.table('Kepler2.dat')[[1]] # KIC 007609553
length(which(is.na(Kepler1))) / length(Kepler1) # 16% NAs
length(which(is.na(Kepler2))) / length(Kepler2) # 29% NAs
par(mfrow=c(2,1)) ; par(mar=c(5,4,1,2))
plot(Kepler1, type='l', xlab='Time')
plot(Kepler2, type='l', xlab='Time')
cat(' Kepler 1: Median flux = ', median(Kepler1, na.rm=TRUE),
' with InterQuartile Range = ', IQR(Kepler1, na.rm=TRUE))
par(mfrow=c(2,1)) ; par(mar=c(5,4,1,2))
acf(Kepler1, na.action=na.pass, ylim=c(-0.05, 0.2),
xlab='Kepler 1 lag', main='', ci.col='black')
hist(Kepler1, freq=FALSE, breaks=200, main='', xlim=c(-20,20),
xlab='Kepler 1 values')
library(MASS) # Comparison with normal distribution
Kep1_mn <- fitdistr(Kepler1[!is.na(Kepler1)], 'normal')[[1]][1]
Kep1_sd <- fitdistr(Kepler1[!is.na(Kepler1)], 'normal')[[1]][2]
curve(dnorm(x, Kep1_mn, Kep1_sd), -20, 20, add=TRUE)
if(!require("nortest", quietly=T)) {
install.packages("nortest", repos="https://cloud.r-project.org", dependencies=TRUE)
}; library(nortest)
ad.test(Kepler1)
cor.test(1:length(Kepler1), Kepler1, method='kendall')$p.value # Test for trend
Kep1_arima <- arima(Kepler1, order=c(2,1,2)) # Autoregressive model
print(Kep1_arima)# look at a dummary of the 'arima' function output
str(Kep1_arima)  # look in detail at the 'arima' function output
acf(Kep1_arima$residuals, na.action=na.pass, ylim=c(-0.05, 0.2), xlab='Kepler 1 lag', ci.col='black')  # shows excellent improvement in autocorrelation ...
IQR(Kepler1, na.rm=TRUE) ; IQR(Kep1_arima$residuals, na.rm=TRUE)  # ... but little improvement in noise
ad.test(Kep1_arima$residuals) # test for normality
if(!require("imputeTS", quietly=T)) {
install.packages("imputeTS", repos="https://cloud.r-project.org", dependencies=TRUE)
}; library(imputeTS)
arima_resids <- na_kalman(Kep1_arima$residuals)
par(mfrow=c(3,1)) ; par(mar=c(5,4,1,2))
spec.pgram(Kepler2_impute, xlim=c(0,0.005), spans=5, taper=0.0,
main='', ylab='Fourier', sub='')
if(!require("lomb", quietly=T)) {
install.packages("lomb", repos="https://cloud.r-project.org", dependencies=TRUE)
}; library(lomb)
lsp(Kepler2, from=0.00, to=0.005, ylab='Lomb-Scargle', main='')
if(!require("RobPer", quietly=T)) {
install.packages("RobPer", repos="https://cloud.r-project.org", dependencies=TRUE)
}; library(RobPer)
if(!require("waveslim", quietly=T)) {
install.packages("waveslim", repos="https://cloud.r-project.org", dependencies=TRUE)
}; library(waveslim)
if(!require("wavethresh", quietly=T)) {
install.packages("wavethresh", repos="https://cloud.r-project.org", dependencies=TRUE)
}; library(wavethresh)
?ar
?goftest
?Box.test
?ad.test
